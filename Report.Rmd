---
title: "Report"
output:
  pdf_document: 
    latex_engine: xelatex
  #html_document: 
    toc: true
    number_sections: true
    df_print: kable
---

# Introduction

This report is part of the final course in the HarvardX Data Science Professional Certificate, Capstone. The aim of the project is to create a movie recommendation system using the MovieLens dataset. Thus, to achieve this goal we will train a machine learning algorithm using the inputs in one subset to predict movie ratings in the validation set.

According to Michael Hahsler: "Predicting ratings and creating personalized recommendations for products like books, songs or movies online came a long way from Information Lense, the first system using social filtering created by Malone, Grant, Turbak, Brobst, and Cohen (1987) more than 20 years ago. Today recommender systems are an accepted technology used by market leaders in several industries (e.g., by Amazon, Netflix and Pandora). Recommender systems apply statistical and knowledge discovery techniques to the problem of making product recommendations based on previously recorded data (Sarwar, Karypis, Konstan, and Riedl 2000). Such recommendations can help to improve the conversion rate by helping the customer to find products she/he wants to buy faster, promote cross-selling by suggesting additional products and can improve customer loyalty through creating a value-added relationship (Schafer, Konstan, and Riedl 2001). The importance and the economic impact of research in this field is reflected by the Netflix Prize, a challenge to improve the predictions of Netflixâ€™s movie recommender system by more than 10% in terms of the root mean square error. The grand price of 1 million dollar was awarded in September 2009 to the Belcore Pragmatic Chaos team."

We will be creating our own recommendation system using the tools we have learned throughout the courses. Thus, we will use R language to write the code, and its libraries, which will help us to complete the task. We will wrangle data, visualize it, and create a machine learning model, which will run using probability and linear regression concepts.

Because the computation will be run on a personal computer, We will use the 10M version of the MovieLens dataset to make it a little easier. This dataset is available on "http://files.grouplens.org/datasets/movielens/ml-10m.zip". Thus, to start we will: install the libraries that will help us to perform our task; download the dataset; create a training and a test set, which will be called edx set and validation set respectively. Then, we will do some data exploration. In sequence we will create a moded.

After that, we will measure the quality of our models by RMSE, which stands for root mean square deviation.It is the same measurament the Netflix used in its Challenge, yet in our case the goal is to reach a RMSE less than 0,87750. 


#Methods/ analysis
The first step is to define what libraries we are going to use. We will need the tidyverse package to manipulate the dataset, and the caret package to develop our machine learning model. 

Then, we will create the train set, which will be called edx, and the test set, which will be called validation. 


```{r setup, include=TRUE, warning=FALSE}

knitr::opts_chunk$set(echo = TRUE)

#############################################################
# Create edx set, and validation set
#############################################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

#download the dataset
dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- read.table(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                      col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data

set.seed(1)
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set

validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set

removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)

```


Once our datasets are created, we can examine it to get a better view of what we are dealing with.  
First we can check names of the collumns: 

```{r,include=TRUE, warning=FALSE}
names(edx)
```

We can also see that each row shows the rating that an user has given to a movie. For isntance, we can see the first ten rows of the data:

```{r,include=TRUE, warning=FALSE}
head(edx, n = 10L)
```

To find out the number of movies, we will use the code below:

```{r,include=TRUE, warning=FALSE}
length(unique(edx$movieId))
```

Similarly we can discovery how many unique users there are in the dataset:

```{r,include=TRUE, warning=FALSE}
length(unique(edx$userId))
```

Using the stringi, and stringr packages, we can work with strings. As a consequence, we can determine the genres of the movies. 

```{r,include=TRUE, warning=FALSE}
if(!require(stringi)) install.packages("stringi", repos = "http://cran.us.r-project.org")
if(!require(stringr)) install.packages("stringr", repos = "http://cran.us.r-project.org")

genres = unique(unlist(str_extract_all(edx$genres,"[A-Z][^|]+")))
genres
```

Then, we can see the number of movie grouped by genre. 

```{r,include=TRUE, warning=FALSE}
#count the number of movies group by genre
count_genres = sapply(genres, function(x){
  n = sum(str_count(edx$genres,x))
})

#plot the number of movies group by genre (descending order)
data.frame(genres, count_genres) %>%
  mutate(genres = reorder(genres, count_genres)) %>%
  ggplot(aes(genres, count_genres)) +
  geom_bar(stat="identity") +
  coord_flip() +
  theme(axis.text.y = element_text(size = 6)) +
  xlab("")
```

Then, we can find out the distribution of ratings. 

```{r,include=TRUE, warning=FALSE}
edx %>% group_by(rating) %>% summarise(n = n()) %>% 
  ggplot(aes(rating,n)) + geom_bar(stat = "identity")
```

We can see that there is a user effect using the code below:

```{r,include=TRUE, warning=FALSE}
user_rating = edx %>% group_by(userId) %>% summarise(avg_rating = mean(rating),sd_rating = sd(rating))
user_rating %>% ggplot(aes(avg_rating)) + geom_histogram(bins = 20)
rm(user_rating)

```

Similarly, there is a movie effect

```{r,include=TRUE, warning=FALSE}
movie_rating =  edx %>% group_by(movieId) %>% summarise(avg_rating = mean(rating),sd_rating = sd(rating))
movie_rating %>% ggplot(aes(avg_rating)) + geom_histogram(bins = 20)
rm(movie_rating)

```

And, genre effect

```{r,include=TRUE, warning=FALSE}
ratings_genres = map_df(genres, function(x){
  n = edx %>% filter(str_detect(edx$genres,x)) %>% summarise(Genre = x, avg = mean(rating), sd= sd(rating))
})
ratings_genres %>% knitr::kable()
```

And also, a time effect

```{r,include=TRUE, warning=FALSE}
library(lubridate)
edx$date = as_datetime(edx$timestamp, origin = "1970-01-01")
edx$year = year(edx$date)

edx %>% mutate(timest = round_date(date, "year"))%>% group_by(timest) %>%
  summarise(avg_rating = mean(rating)) %>%
  ggplot(aes(timest,avg_rating)) + geom_point()

```

Therefore, we can create a model combining these effects. In fact, we are going to try the follow model to predict the rating $Y_{u,i}$, that a user $u$ can give to a movie $i$, which has some genre $g$.

$$Y_{u,i} = \mu + b_{i} + b_{u} +\epsilon_{u,i}$$  

Although this model is similar to a linear regression model, we are not going to use the lm fuction because of this code will run on a personal computer. 


#Results

First, we can calculate the average and considiring this as a model we can calcule RMSE, which will help us to evaluate the improvemment of our models when we complete the following steps. 


```{r,include=TRUE, warning=FALSE}
####just the average
mu_hat <- mean(edx$rating)
mu_hat

naive_rmse <- RMSE(validation$rating, mu_hat)
naive_rmse

rmse_results <- data_frame(method = "Just the average", RMSE = naive_rmse)
rmse_results %>% knitr::kable()

```

Since, there is a genre effect, we can calculate the average for it genre. Because, of each movie has more than one genre, we will considerate the genre effect as the mean of average of all genres that define a movie. 

```{r,include=TRUE, warning=FALSE}
#####genre effect
genres_avgs = map_dbl(1:length(unique(edx$genres)), function(x){
  mu = mean(ratings_genres$avg[str_detect(unique(edx$genres)[x],ratings_genres$Genre)])
})
genres_mu = data.frame(genres = unique(edx$genres), mu = genres_avgs, stringsAsFactors = F)
avg_genres = edx %>% 
  left_join(genres_mu, by="genres") 

predicted_ratings = validation %>%
  left_join(genres_mu, by="genres") %>%
  .$mu


model_1_rmse = caret::RMSE(predicted_ratings, validation$rating)
rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Genre Effect Model",  
                                     RMSE = model_1_rmse ))

rmse_results
```


Altough, it is possiblie to see a improvement in the RMSE, it was not significant considering just the genre effect. Thus, the next step is to use the movie effect. 

```{r,include=TRUE, warning=FALSE}

movie_avgs <- edx %>% 
  group_by(movieId) %>% 
  summarize(b_i = mean(rating - mu_hat))

predicted_ratings <- validation %>% 
  left_join(movie_avgs, by='movieId') %>%
  mutate(pred = mu_hat + b_i ) %>%
  .$pred


model_2_rmse <- RMSE(predicted_ratings, validation$rating)

rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Movie Effect Model",  
                                     RMSE = model_2_rmse ))
rmse_results

```

Once we have added the movie effect, we can improve the model considering the user effect. 

```{r,include=TRUE, warning=FALSE}
#####users effect
user_avgs <- edx %>% 
  left_join(movie_avgs, by='movieId') %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mu_hat - b_i))

predicted_ratings <- validation %>% 
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  mutate(pred = mu_hat + b_i + b_u) %>%
  .$pred

model_3_rmse <- RMSE(predicted_ratings, validation$rating)

rmse_results <- bind_rows(rmse_results,
                          data_frame(method="User + Movie Effect Model",  
                                     RMSE = model_3_rmse ))
rmse_results
```

We can see that the model that uses the genre, the movie, and the user effect has given us a RMSE of 0,865, which is less than our target of 0,87750. 

#Conclusion

In this project, we have created a recommender model. It works similar to a linear regression and has achived a final RMSE of 0,865, which is less than our initial target of 0,8775. Thus we have had sucess in our project.
Although we have reached our goal, further improvement could be achieved by other techniques, such as regularization and boostraping. The regularization will help us to remove the impact than some movies are more rated than others. 


#References

[1] F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4, Article 19 (December 2015), 19 pages. DOI=http://dx.doi.org/10.1145/2827872

[2] Michael Hahsler (2019). recommenderlab: Lab for Developing and Testing Recommender Algorithms. R package version 0.2-4.https://github.com/mhahsler/recommenderlab

